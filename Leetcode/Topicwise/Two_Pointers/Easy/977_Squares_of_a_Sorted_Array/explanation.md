### Problem Understanding

The problem asks us to take an integer array, `nums`, which is guaranteed to be sorted in non-decreasing order, and return a *new* array containing the squares of every number in `nums`. Crucially, this resulting array must also be sorted in non-decreasing order.

The challenge arises because squaring negative numbers reverses their relative order. For example, in the input $[-5, -2, 1, 4]$, the squares are $[25, 4, 1, 16]$. When sorted, this becomes $[1, 4, 16, 25]$. We need an efficient way to square the elements and sort them simultaneously without resorting to a general $O(N \log N)$ sorting algorithm after squaring.

### Approach / Intuition

A naive approach would be to square every number and then use a standard sorting algorithm (like `Arrays.sort()` in Java), resulting in $O(N \log N)$ time complexity. Since the input array is already sorted, we can leverage this property to achieve an optimal $O(N)$ solution using the **Two Pointers** technique.

**Core Intuition:**
When we square the elements, the smallest resulting squares will be generated by the numbers closest to zero. In a sorted array, the numbers closest to zero are located near the boundary where negative numbers transition to non-negative numbers.

The provided solution implements a **Center-Out Merge Strategy**:

1.  **Find the Pivot:** Locate the index (`ind`) where the array transitions from negative numbers (or zero) to positive numbers.
2.  **Initialize Pointers:** Set a left pointer (`l`) to the last negative number (just before the pivot) and a right pointer (`r`) to the first non-negative number (the pivot).
3.  **Merge:** Since the numbers further away from zero produce larger squares, we continuously compare the *absolute values* of the elements pointed to by `l` and `r`.
    *   The element with the smaller absolute value is closer to zero, so its square is the next smallest element in the final sorted array.
    *   We square that element, place it into the result array, and move the corresponding pointer (left moves left, right moves right).
4.  **Cleanup:** Once one pointer runs out of bounds, the remaining elements in the other section (all negatives or all positives) are already sorted by magnitude, so we simply square and append them.

This approach guarantees that we build the result array `ans` in sorted order from smallest to largest in a single pass.

### Data Structures and Algorithms

1.  **Data Structure:**
    *   **Array:** Used for the input (`nums`) and the output (`ans`).

2.  **Algorithms:**
    *   **Linear Scan:** Used initially to find the pivot point (`ind`) where the array transitions from negative to non-negative numbers.
    *   **Two Pointers:** The core algorithm. Pointers `l` and `r` are used to simultaneously traverse the negative and non-negative sections of the array, facilitating an efficient $O(N)$ merge operation.
    *   **Merge Strategy:** The comparison and placement logic is analogous to the merge step in Merge Sort, where two sorted lists (the squares of the negative numbers, and the squares of the non-negative numbers) are combined into one sorted list.

### Code Walkthrough

```java
class Solution {
    public int[] sortedSquares(int[] nums) {
        int n = nums.length;
        int[] ans = new int[n]; // Result array
        int ind = n;            // Index of the first non-negative number (pivot)
        int ptr = 0;            // Pointer for the result array 'ans'

        // 1. Find the pivot (index of the first non-negative number)
        for(int i = 0; i<n; i++) {
            if(nums[i] >= 0) {
                ind = i;
                break;
            }
        }

        // 2. Initialize Two Pointers: l points to the last negative, r points to the first non-negative
        int l = ind-1; 
        int r = ind;

        // 3. Main Merge Loop: Compare absolute values of elements near the center
        while(l>=0 && r<n) {
            // Compare absolute values to find the number closest to zero
            if(Math.abs(nums[l]) < Math.abs(nums[r])) {
                // Left element is closer to zero (smaller square)
                ans[ptr++] = nums[l]*nums[l];
                l--;
            } else {
                // Right element is closer to zero or equal (smaller square)
                ans[ptr++] = nums[r]*nums[r];
                r++;
            }
        }

        // 4. Cleanup Loop 1: Handle remaining negative numbers (if any)
        // Since l is decreasing, the remaining negative numbers are increasing in magnitude, 
        // meaning their squares are increasing.
        while(l>=0) {
            ans[ptr++] = nums[l]*nums[l];
            l--;
        }

        // 5. Cleanup Loop 2: Handle remaining non-negative numbers (if any)
        // Since r is increasing, the remaining positive numbers are increasing in magnitude, 
        // meaning their squares are increasing.
        while(r<n) {
            ans[ptr++] = nums[r]*nums[r];
            r++;
        }

        return ans;
    }
}
```

### Time and Space Complexity

#### Time Complexity: $O(N)$

The solution involves three main phases, all of which are linear passes over the data:

1.  **Finding the Pivot:** The initial `for` loop iterates at most $N$ times. ($O(N)$)
2.  **Merging:** The main `while` loop iterates exactly $k$ times, where $k$ is the number of elements processed before one pointer goes out of bounds.
3.  **Cleanup:** The two final `while` loops iterate through the remaining $N-k$ elements.

Since every element in the input array `nums` is processed, squared, and placed into the output array exactly once, the total time complexity is linear, $O(N)$.

#### Space Complexity: $O(N)$

We initialize a new array `ans` of size $N$ to store the result. We use only a few constant space variables (`n`, `ind`, `ptr`, `l`, `r`).

Therefore, the space complexity is dominated by the storage required for the output array, resulting in $O(N)$ space complexity.